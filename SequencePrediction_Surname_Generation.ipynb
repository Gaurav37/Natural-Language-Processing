{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "264px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": "5",
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e368bd3acaa4c89a5904b5654ef483f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c31c76226a9e428f9a47565680b6fac0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c4ac54b28ef24f0c917173aea050d664",
              "IPY_MODEL_c1ea97c2ac01409daa6418cfd59a4799"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "c31c76226a9e428f9a47565680b6fac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "c4ac54b28ef24f0c917173aea050d664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_512e0fa210df43288bd88c3e556dbff1",
            "_dom_classes": [],
            "description": "training routine:  94%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 94,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7e47291b95a459280eb08e0fe873423"
          },
          "model_module_version": "1.5.0"
        },
        "c1ea97c2ac01409daa6418cfd59a4799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_97e99d25da4e4695855b0c7b76779710",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 94/100 [02:57&lt;00:11,  1.86s/it, sample1=Magrasmetsyy, sample2=Chav]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26965255144d4d28adae6a138af38c89"
          },
          "model_module_version": "1.5.0"
        },
        "512e0fa210df43288bd88c3e556dbff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "e7e47291b95a459280eb08e0fe873423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "97e99d25da4e4695855b0c7b76779710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "26965255144d4d28adae6a138af38c89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaurav37/Natural-Language-Processing/blob/main/SequencePrediction_Surname_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crOQ7QBjhrgV"
      },
      "source": [
        "# Sequence Prediction: Surname Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7mWak9NZqsE"
      },
      "source": [
        "In this experiment, you will explore a simple sequence prediction task: Text generation using a Gated Recurrent Unit (GRU). Like an LSTM, this is an example of a recurrent neural network, but since it has fewer parameters, it should be more appropriate for a smaller dataset.\n",
        "\n",
        "The GRU computes a probability distribution over the set of possible characters in the surname vocabulary for each time step. We use these probability distributions to generate new surnames. You are given starter code that trains a SurnameGenerationModel on the [surname dataset](https://github.com/jasoriya/CS6120-PS2-support/blob/master/data/surnames/surnames_with_splits.csv) to generate new surnames by learning from the training data. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJkLtjvSaf5P"
      },
      "source": [
        "Your task is to understand this code and plot the over all perplxity of GRU model as a function of the hidden representation size (K) and the number of characters already observed. You will see **TODO** prompts in the following cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEjYmZ5Shrgb"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIbXsKQLhrgd"
      },
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "\n",
        "import numpy as np\n",
        "import httpimport\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "# import data preprocessing and modeling functions from https://github.com/jasoriya/CS6120-PS2-support/tree/master/utils\n",
        "with httpimport.remote_repo(['data_vectorization','model','helper'], 'https://raw.githubusercontent.com/jasoriya/CS6120-PS2-support/master/utils/'):\n",
        "  from data_vectorization import Vocabulary, SequenceVocabulary, SurnameVectorizer, SurnameDataset, generate_batches\n",
        "  from model import SurnameGenerationModel, sample_from_model, decode_samples\n",
        "  from helper import make_train_state, update_train_state, normalize_sizes, compute_accuracy, sequence_loss, set_seed_everywhere, handle_dirs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwQ3H6hhhrhM"
      },
      "source": [
        "### Settings and some prep work\n",
        "\n",
        "**TODO**: \n",
        "- Give path to a directory where the model should be saved\n",
        "- Give hidden state size (`rnn_hidden_size`) for the GRU model (experiment with different levels)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6ELbWoHhrhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c593bf-5ab7-4542-fc3a-49190e82e5cb"
      },
      "source": [
        "args = Namespace(\n",
        "    # Data and Path information\n",
        "    surname_csv=\"https://raw.githubusercontent.com/jasoriya/CS6120-PS2-support/master/data/surnames/surnames_with_splits.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir= \"/\", # give path here\n",
        "    # Model hyper parameters\n",
        "    char_embedding_size=32,\n",
        "    rnn_hidden_size= 16, # give hidden size\n",
        "    # Training hyper parameters\n",
        "    seed=1337,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=128,\n",
        "    num_epochs=100,\n",
        "    early_stopping_criteria=5,\n",
        "    # Runtime options\n",
        "    catch_keyboard_interrupt=True,\n",
        "    cuda=True,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    reload_from_files=False,\n",
        ")\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"Expanded filepaths: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "    \n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "    \n",
        "print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# handle dirs\n",
        "handle_dirs(args.save_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\t/vectorizer.json\n",
            "\t/model.pth\n",
            "Using CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK7rHgKPhrhS"
      },
      "source": [
        "### Initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zdUk04AhrhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71872055-45de-490a-e716-070d3549a61d"
      },
      "source": [
        "if args.reload_from_files:\n",
        "    # training from a checkpoint\n",
        "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv,\n",
        "                                                              args.vectorizer_file)\n",
        "else:\n",
        "    # create dataset and vectorizer\n",
        "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "\n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "model = SurnameGenerationModel(char_embedding_size=args.char_embedding_size,\n",
        "                               char_vocab_size=len(vectorizer.char_vocab),\n",
        "                               rnn_hidden_size=args.rnn_hidden_size,\n",
        "                               padding_idx=vectorizer.char_vocab.mask_index)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 16, batch_first=True)\n",
            "  (fc): Linear(in_features=16, out_features=88, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy5dwODVhrhX"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "jIr6FBQWhrhY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "8e368bd3acaa4c89a5904b5654ef483f",
            "c31c76226a9e428f9a47565680b6fac0",
            "c4ac54b28ef24f0c917173aea050d664",
            "c1ea97c2ac01409daa6418cfd59a4799",
            "512e0fa210df43288bd88c3e556dbff1",
            "e7e47291b95a459280eb08e0fe873423",
            "97e99d25da4e4695855b0c7b76779710",
            "26965255144d4d28adae6a138af38c89"
          ]
        },
        "outputId": "f3329c9d-38b0-4422-e301-bcb777ac4cea"
      },
      "source": [
        "mask_index = vectorizer.char_vocab.mask_index\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "#train_bar = tqdm_notebook(desc='split=train',\n",
        "#                          total=dataset.get_num_batches(args.batch_size), \n",
        "#                          position=1, \n",
        "#                          leave=True)\n",
        "dataset.set_split('val')\n",
        "#val_bar = tqdm_notebook(desc='split=val',\n",
        "#                        total=dataset.get_num_batches(args.batch_size), \n",
        "#                        position=1, \n",
        "#                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        model.train()\n",
        "        \n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------    \n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the  running loss and running accuracy\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            #train_bar.set_postfix(loss=running_loss,\n",
        "            #                      acc=running_acc,\n",
        "            #                      epoch=epoch_index)\n",
        "            #train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        model.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # compute the output\n",
        "            y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "            # compute the  running loss and running accuracy\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            \n",
        "            # Update bar\n",
        "            #val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "            #                epoch=epoch_index)\n",
        "            #val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=model, \n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "        \n",
        "        # move model to cpu for sampling\n",
        "        model = model.cpu()\n",
        "        sampled_surnames = decode_samples(\n",
        "            sample_from_model(model, vectorizer, num_samples=2), \n",
        "            vectorizer)\n",
        "        epoch_bar.set_postfix(sample1=sampled_surnames[0], \n",
        "                              sample2=sampled_surnames[1])\n",
        "        # move model back to whichever device it should be on\n",
        "        model = model.to(args.device)\n",
        "        \n",
        "        #train_bar.n = 0\n",
        "        #val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "        \n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e368bd3acaa4c89a5904b5654ef483f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1pV10L3hrhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae87000a-5386-4621-9b28-94e66648d671"
      },
      "source": [
        "np.random.choice(np.arange(len(vectorizer.nationality_vocab)), replace=True, size=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crgnIUPghrhg"
      },
      "source": [
        "# compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_acc = 0.\n",
        "model.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "    # compute the loss\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "    # compute the accuracy\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss \n",
        "train_state['test_acc'] = running_acc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldfJK8jBgbnT"
      },
      "source": [
        "**TODO**: Write code to compute the perplexity of the test corpus, the accuracy of a character-prediction task, and the perplexity of the predictive distribution given increasing amounts of context. For this last metric, you want to compute the perplexity of predicting the first character (given nothing to the left), the perplexity of predicting the second character (given the first), and so on, up to the perplexity of predicting the n-th character (given the first 1 to n-1 characters). Unlike an n-gram model, the recurrent model can encode arbitrarily long histories, although it will probably make more use of the nearby context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfzssGYjhrhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9c10d9c-c142-4af2-d325-b3670071aa68"
      },
      "source": [
        "import math\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,running_loss))) # compute and print perplexity here\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.665981849034627;\n",
            "Test perplexity: 6.34659089672326;\n",
            "Test Accuracy: 22.338558822796756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FCywMZ6hrhm"
      },
      "source": [
        "## Inference\n",
        "To see the names that the model generates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTbrH4dBhrho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9147c32b-0284-4d56-a163-2ebcebc824e3"
      },
      "source": [
        "# number of names to generate\n",
        "num_names = 10\n",
        "model = model.cpu()\n",
        "# Generate nationality hidden state\n",
        "sampled_surnames = decode_samples(\n",
        "    sample_from_model(model, vectorizer, num_samples=num_names), \n",
        "    vectorizer)\n",
        "# Show results\n",
        "print (\"-\"*15)\n",
        "for i in range(num_names):\n",
        "    print (sampled_surnames[i])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------\n",
            "Kafnraosy\n",
            "Ko\n",
            "Pcohretaer\n",
            "Csepellhhovn\n",
            "écvenbgyrsovr\n",
            "Hanlyere\n",
            "Kanrair\n",
            "Muchenvayn\n",
            "Biuvoyin\n",
            "Seguibey\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjgqHfp7ggAj"
      },
      "source": [
        "**TODO**: Train the GRU model given above multiple times for different levels of `rnn_hidden_size`. For each of these models, plot the average perplexity as a function of the number of characters of the name observed so far. Explain your observations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsKEX4ylUUFP"
      },
      "source": [
        "# Your plotting code here\n",
        "\n",
        "#Lets create models first:\n",
        "def create_models_diff_hidden(rnn_hidden_size):\n",
        "  args = Namespace(\n",
        "    # Data and Path information\n",
        "    surname_csv=\"https://raw.githubusercontent.com/jasoriya/CS6120-PS2-support/master/data/surnames/surnames_with_splits.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir= \"/\", # give path here\n",
        "    # Model hyper parameters\n",
        "    char_embedding_size=32,\n",
        "    rnn_hidden_size= rnn_hidden_size, # give hidden size\n",
        "    # Training hyper parameters\n",
        "    seed=1337,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=128,\n",
        "    num_epochs=100,\n",
        "    early_stopping_criteria=5,\n",
        "    # Runtime options\n",
        "    catch_keyboard_interrupt=True,\n",
        "    cuda=True,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    reload_from_files=False,\n",
        "  )\n",
        "\n",
        "  if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,args.vectorizer_file)\n",
        "    args.model_state_file = os.path.join(args.save_dir,args.model_state_file)\n",
        "    print(\"Expanded filepaths: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "      \n",
        "      \n",
        "  # Check CUDA\n",
        "  if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "  args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "      \n",
        "  print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "  # Set seed for reproducibility\n",
        "  set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "  # handle dirs\n",
        "  handle_dirs(args.save_dir)\n",
        "  if args.reload_from_files:\n",
        "    # training from a checkpoint\n",
        "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv,args.vectorizer_file)\n",
        "  else:\n",
        "    # create dataset and vectorizer\n",
        "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "\n",
        "  vectorizer = dataset.get_vectorizer()\n",
        "  model = SurnameGenerationModel(char_embedding_size=args.char_embedding_size,\n",
        "                               char_vocab_size=len(vectorizer.char_vocab),\n",
        "                               rnn_hidden_size=args.rnn_hidden_size,\n",
        "                               padding_idx=vectorizer.char_vocab.mask_index)\n",
        "  print(model)\n",
        "  mask_index = vectorizer.char_vocab.mask_index\n",
        "\n",
        "  model = model.to(args.device)\n",
        "\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                            mode='min', factor=0.5,\n",
        "                                            patience=1)\n",
        "  train_state = make_train_state(args)\n",
        "\n",
        "  #epoch_bar = tqdm_notebook(desc='training routine', \n",
        "  #                          total=args.num_epochs,\n",
        "  #                          position=0)\n",
        "\n",
        "  dataset.set_split('train')\n",
        "  #train_bar = tqdm_notebook(desc='split=train',\n",
        "  #                          total=dataset.get_num_batches(args.batch_size), \n",
        "  #                          position=1, \n",
        "  #                          leave=True)\n",
        "  dataset.set_split('val')\n",
        "  #val_bar = tqdm_notebook(desc='split=val',\n",
        "  #                        total=dataset.get_num_batches(args.batch_size), \n",
        "  #                        position=1, \n",
        "  #                        leave=True)\n",
        "\n",
        "  try:\n",
        "\n",
        "      for epoch_index in range(args.num_epochs):\n",
        "          train_state['epoch_index'] = epoch_index\n",
        "\n",
        "          # Iterate over training dataset\n",
        "\n",
        "          # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "          dataset.set_split('train')\n",
        "          batch_generator = generate_batches(dataset, \n",
        "                                            batch_size=args.batch_size, \n",
        "                                            device=args.device)\n",
        "          running_loss = 0.0\n",
        "          running_acc = 0.0\n",
        "          model.train()\n",
        "          \n",
        "          for batch_index, batch_dict in enumerate(batch_generator):\n",
        "              # the training routine is these 5 steps:\n",
        "\n",
        "              # --------------------------------------    \n",
        "              # step 1. zero the gradients\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # step 2. compute the output\n",
        "              y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "              # step 3. compute the loss\n",
        "              loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "\n",
        "              # step 4. use loss to produce gradients\n",
        "              loss.backward()\n",
        "\n",
        "              # step 5. use optimizer to take gradient step\n",
        "              optimizer.step()\n",
        "              # -----------------------------------------\n",
        "              # compute the  running loss and running accuracy\n",
        "              running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "              acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "              running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "              \n",
        "          train_state['train_loss'].append(running_loss)\n",
        "          train_state['train_acc'].append(running_acc)\n",
        "\n",
        "          # Iterate over val dataset\n",
        "\n",
        "          # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "          dataset.set_split('val')\n",
        "          batch_generator = generate_batches(dataset, \n",
        "                                            batch_size=args.batch_size, \n",
        "                                            device=args.device)\n",
        "          running_loss = 0.\n",
        "          running_acc = 0.\n",
        "          model.eval()\n",
        "\n",
        "          for batch_index, batch_dict in enumerate(batch_generator):\n",
        "              # compute the output\n",
        "              y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "              # step 3. compute the loss\n",
        "              loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "              # compute the  running loss and running accuracy\n",
        "              running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "              acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "              running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "              \n",
        "              # Update bar\n",
        "              #val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "              #                epoch=epoch_index)\n",
        "              #val_bar.update()\n",
        "\n",
        "          train_state['val_loss'].append(running_loss)\n",
        "          train_state['val_acc'].append(running_acc)\n",
        "\n",
        "          train_state = update_train_state(args=args, model=model, \n",
        "                                          train_state=train_state)\n",
        "\n",
        "          scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "          if train_state['stop_early']:\n",
        "              break\n",
        "          \n",
        "          # move model to cpu for sampling\n",
        "          model = model.cpu()\n",
        "          sampled_surnames = decode_samples(\n",
        "              sample_from_model(model, vectorizer, num_samples=2), \n",
        "              vectorizer)\n",
        "          #epoch_bar.set_postfix(sample1=sampled_surnames[0], \n",
        "          #                      sample2=sampled_surnames[1])\n",
        "          # move model back to whichever device it should be on\n",
        "          model = model.to(args.device)\n",
        "          \n",
        "          #train_bar.n = 0\n",
        "          #val_bar.n = 0\n",
        "          #epoch_bar.update()\n",
        "          \n",
        "  except KeyboardInterrupt:\n",
        "      print(\"Exiting loop\")\n",
        "  train_state['model_filename'] = \"./{}_hidden.pt\".format(str(rnn_hidden_size))\n",
        "  torch.save(model.state_dict(), train_state['model_filename'])\n",
        "  return args, dataset, vectorizer, train_state, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbQkzJLOfTxx",
        "outputId": "2066b91f-968f-4f6f-8097-a6dbedf66290"
      },
      "source": [
        "model_rnn={}\n",
        "for hidden_size in [32,64,128,256]:\n",
        "  model_rnn[hidden_size]=create_models_diff_hidden(hidden_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\t/vectorizer.json\n",
            "\t/model.pth\n",
            "Using CUDA: True\n",
            "SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 32, batch_first=True)\n",
            "  (fc): Linear(in_features=32, out_features=88, bias=True)\n",
            ")\n",
            "Expanded filepaths: \n",
            "\t/vectorizer.json\n",
            "\t/model.pth\n",
            "Using CUDA: True\n",
            "SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 64, batch_first=True)\n",
            "  (fc): Linear(in_features=64, out_features=88, bias=True)\n",
            ")\n",
            "Expanded filepaths: \n",
            "\t/vectorizer.json\n",
            "\t/model.pth\n",
            "Using CUDA: True\n",
            "SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 128, batch_first=True)\n",
            "  (fc): Linear(in_features=128, out_features=88, bias=True)\n",
            ")\n",
            "Expanded filepaths: \n",
            "\t/vectorizer.json\n",
            "\t/model.pth\n",
            "Using CUDA: True\n",
            "SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 256, batch_first=True)\n",
            "  (fc): Linear(in_features=256, out_features=88, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b2GG_0UEaHo",
        "outputId": "350a1cef-eb5f-43ba-8529-cffbc41a5b27"
      },
      "source": [
        "print(model_rnn.items())\n",
        "!pwd\n",
        "!cd ..\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_items([(32, (Namespace(batch_size=128, catch_keyboard_interrupt=True, char_embedding_size=32, cuda=True, device=device(type='cuda'), early_stopping_criteria=5, expand_filepaths_to_save_dir=True, learning_rate=0.001, model_state_file='/model.pth', num_epochs=100, reload_from_files=False, rnn_hidden_size=32, save_dir='/', seed=1337, surname_csv='https://raw.githubusercontent.com/jasoriya/CS6120-PS2-support/master/data/surnames/surnames_with_splits.csv', vectorizer_file='/vectorizer.json'), <data_vectorization.SurnameDataset object at 0x7f99a0059470>, <data_vectorization.SurnameVectorizer object at 0x7f99a0059f98>, {'stop_early': False, 'early_stopping_step': 0, 'early_stopping_best_val': 2.540661831696828, 'learning_rate': 0.001, 'epoch_index': 99, 'train_loss': [4.0794039090474445, 3.1958331425984707, 2.9439173936843868, 2.8316943407058712, 2.76467813650767, 2.7252426584561666, 2.6958925525347395, 2.672549136479697, 2.6612891435623176, 2.649063861370087, 2.6366780400276184, 2.6269029259681704, 2.6177956700325016, 2.613527158896129, 2.6069478670756014, 2.5982005596160893, 2.5922545989354444, 2.587104237079621, 2.5818052728970837, 2.578605635960897, 2.5746017893155404, 2.567859355608623, 2.567266654968263, 2.5643039822578433, 2.561387228965759, 2.5560395161310825, 2.5549394607543956, 2.5508259693781534, 2.548431320985158, 2.5458537141482043, 2.544845577081045, 2.5405239701271047, 2.5389008601506546, 2.5344201525052403, 2.5336744070053094, 2.534740436077118, 2.5318711956342073, 2.5300810297330223, 2.5348247925440477, 2.536303969224294, 2.5328496972719825, 2.5325970927874235, 2.533626250425975, 2.534759732087453, 2.5330631931622825, 2.530373577276866, 2.530243543783824, 2.5337457378705346, 2.5308800657590242, 2.535258396466573, 2.534379367033641, 2.532462648550669, 2.531859099864959, 2.531011656920116, 2.5312011043230696, 2.532686567306518, 2.52954980134964, 2.5308250466982525, 2.530941915512086, 2.534668374061585, 2.530747159322103, 2.530849738915762, 2.534034661451976, 2.535231689612071, 2.5346598863601693, 2.5304602185885106, 2.5343890587488818, 2.532762432098388, 2.5312074939409888, 2.5334492286046344, 2.531370107332866, 2.5306398948033655, 2.5348407109578455, 2.533620746930441, 2.5315772016843154, 2.530066831906637, 2.5312834501266477, 2.5335805177688604, 2.5344206929206856, 2.532711549599965, 2.532686769962311, 2.535721961657206, 2.5277962644894916, 2.533064802487692, 2.529881282647451, 2.533453742663065, 2.53222393989563, 2.5321760614713034, 2.531496357917786, 2.5315414230028797, 2.532981991767883, 2.531755908330282, 2.534779763221741, 2.532815941174826, 2.533196711540222, 2.5320859630902612, 2.533637046813965, 2.5315940618515014, 2.531676828861236, 2.528471903006236], 'train_acc': [7.791792068348249, 16.16441410904377, 19.970912949132586, 21.14859157008068, 21.949415123528837, 22.651279099720018, 23.01103531142605, 23.25916358067264, 23.4730849673731, 23.6505123298988, 23.681907573861096, 23.928827700070208, 23.919280476192554, 23.851142363374027, 24.093671650799674, 24.30021267170815, 24.172516285561734, 24.281365374262574, 24.23587116361112, 24.435108270277112, 24.44397816831958, 24.53339940840942, 24.664774945513308, 24.652479504587888, 24.86594206766431, 24.77213101134482, 24.89803501825467, 24.897307629104176, 24.991495823202015, 25.04079653667925, 24.88914331713514, 25.09202390408979, 25.2683080746921, 25.384998366387798, 25.3258629959838, 25.269327576078453, 25.42902675800906, 25.322449421760638, 25.255171044682744, 25.249529512516844, 25.235736481456957, 25.375144806051846, 25.268805704828967, 25.315664697329158, 25.416941454792855, 25.545591872778623, 25.374679548108617, 25.1994924196668, 25.240842891484135, 25.35827861368324, 25.297422880286383, 25.251080425580735, 25.349408254391864, 25.495152958763786, 25.42864739846403, 25.260581838201247, 25.56824038087014, 25.17501237039469, 25.319008246584513, 25.172262052521152, 25.381917445663742, 25.311275315925762, 25.374343875914832, 25.25135880106403, 25.221149664613588, 25.321744580451817, 25.276285270242255, 25.442541454652414, 25.402762104699566, 25.287202132257743, 25.347940380503022, 25.28802818230524, 25.383915460861186, 25.40104409068829, 25.43881967709796, 25.46189632949415, 25.428225240681932, 25.33482324074445, 25.35291990061974, 25.28332557232848, 25.366674993576122, 25.363548638716306, 25.356808332288534, 25.280255196083026, 25.326552083323733, 25.233097720899977, 25.327122847294415, 25.338613349928032, 25.4373670601065, 25.33386020296782, 25.219024701958286, 25.33926448374404, 25.320715978952713, 25.286391175436542, 25.30265828992189, 25.410637224437675, 25.26871994696681, 25.260899822491137, 25.490440480640398, 25.365126161576793], 'val_loss': [3.437449793020884, 3.0378827651341758, 2.8741727670033774, 2.796263635158539, 2.7453129092852278, 2.7015056610107426, 2.687034984429677, 2.6675699949264526, 2.652638018131256, 2.642972032229106, 2.6331019798914594, 2.634863277276357, 2.6268133322397866, 2.622822880744934, 2.6036037405331927, 2.6040412584940595, 2.602428376674652, 2.591577708721161, 2.5936140219370523, 2.5871066451072693, 2.5814098119735718, 2.5846525231997175, 2.5803755720456443, 2.576850752035776, 2.5661502877871194, 2.558065215746562, 2.563601791858673, 2.5574153264363613, 2.555256803830465, 2.561098655064901, 2.558675726254781, 2.555674056212107, 2.5627131660779314, 2.5507982969284058, 2.555949668089549, 2.5581588149070744, 2.5497489968935647, 2.5519512693087263, 2.5525193611780805, 2.5425851742426557, 2.548570772012075, 2.543093164761861, 2.5570862889289856, 2.558349967002869, 2.559758146603902, 2.5472074945767718, 2.5483179092407227, 2.545954465866089, 2.55974022547404, 2.5426961580912275, 2.5508705774943032, 2.5433556636174526, 2.5533668796221414, 2.556112806002299, 2.5459051926930742, 2.5574702620506287, 2.551938732465108, 2.5546579360961914, 2.5446210702260332, 2.5464967489242554, 2.5463226834932966, 2.5446212887763977, 2.540661831696828, 2.541830261548361, 2.547882854938507, 2.5492982069651284, 2.544938862323761, 2.5543373823165894, 2.549977819124858, 2.553997536500295, 2.5513614614804583, 2.548889954884847, 2.5507785280545554, 2.558182497819265, 2.544642190138499, 2.5533921917279563, 2.557843645413717, 2.5524028738339744, 2.552562812964122, 2.551164944966634, 2.547547896703084, 2.549515763918559, 2.551624039808909, 2.5468689600626626, 2.548941433429718, 2.5511278708775835, 2.5583966970443726, 2.544055004914602, 2.5485192537307744, 2.5550090670585632, 2.5542856454849248, 2.5498679876327515, 2.551394701004028, 2.5565178990364075, 2.5533552169799805, 2.5531276861826577, 2.5413091182708736, 2.5554110606511435, 2.5560519297917685, 2.548229376475016], 'val_acc': [11.442981238061975, 18.485742509503332, 20.498787238165054, 21.399604395119656, 21.775045074690766, 22.4829423932469, 22.781886183883902, 23.152516020319556, 23.30963471957502, 23.200502926082855, 23.667347603472624, 23.89267568576295, 23.362375031770508, 24.002215109777612, 23.661990115959497, 24.147214086303112, 24.035765848421963, 24.19574867131071, 24.134927435417854, 24.020242609562757, 24.082126009992358, 24.108566139049092, 24.155505609091627, 24.362245283441904, 24.5297700878448, 24.780415151550844, 24.408086057617105, 24.56855087418741, 25.22416017085309, 24.729002052218224, 24.74479780104943, 24.788898605537494, 24.486267805133597, 25.125983913794055, 24.839240754297844, 24.849482807770382, 24.83785353358059, 24.76993188089271, 24.625024415057517, 25.11598043081455, 24.72505923544038, 25.073778341685678, 24.642776355366983, 24.911538582358595, 24.97594203786941, 24.988986670691652, 24.92177207943156, 24.91686137784752, 24.94456420817998, 25.070700345150097, 24.746034378159187, 25.168210330993777, 24.55960814949872, 24.85432992699658, 25.10325227592893, 24.19655545931406, 24.95761682505486, 24.710465852678322, 25.203440568276406, 25.08581534346643, 25.115042484101103, 25.010413997870952, 24.77870987748775, 24.824860639823093, 25.050564827020725, 24.803285714460706, 25.186223225364166, 25.06854377574576, 24.47524346311652, 25.12414155547675, 24.853509937296778, 24.864289914078306, 24.61103302330381, 24.91579083413014, 25.051720424467465, 24.573558238106283, 24.293009892909907, 25.105970081091314, 24.80701817921211, 24.51299136034152, 24.565207436471674, 25.06573703101379, 24.985179694785902, 24.833486150855858, 25.225359668288334, 25.107094409026253, 24.88898897930341, 24.858070271430687, 25.003762677782653, 24.681665729308126, 24.832927013408497, 25.075423343318683, 24.622137534320956, 24.842607097535335, 25.047168709632057, 24.883395358509713, 24.930492259878147, 24.91866779238864, 24.64773167706674, 25.129006235269866], 'test_loss': -1, 'test_acc': -1, 'model_filename': './32_hidden.pt'}, SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 32, batch_first=True)\n",
            "  (fc): Linear(in_features=32, out_features=88, bias=True)\n",
            "))), (64, (Namespace(batch_size=128, catch_keyboard_interrupt=True, char_embedding_size=32, cuda=True, device=device(type='cuda'), early_stopping_criteria=5, expand_filepaths_to_save_dir=True, learning_rate=0.001, model_state_file='/model.pth', num_epochs=100, reload_from_files=False, rnn_hidden_size=64, save_dir='/', seed=1337, surname_csv='https://raw.githubusercontent.com/jasoriya/CS6120-PS2-support/master/data/surnames/surnames_with_splits.csv', vectorizer_file='/vectorizer.json'), <data_vectorization.SurnameDataset object at 0x7f998e5f3588>, <data_vectorization.SurnameVectorizer object at 0x7f998e5f3978>, {'stop_early': False, 'early_stopping_step': 1, 'early_stopping_best_val': 2.4067189892133083, 'learning_rate': 0.001, 'epoch_index': 99, 'train_loss': [3.7399300495783483, 2.9412961999575304, 2.745340247948965, 2.6615612030029308, 2.6201280315717055, 2.5901231050491327, 2.5698235034942627, 2.5520062247912096, 2.537594989935557, 2.5242361744244897, 2.5128974278767906, 2.5074464162190755, 2.5001673022905977, 2.4871144255002338, 2.48223212560018, 2.475278532505036, 2.4678134957949314, 2.460963507493337, 2.4544272422790523, 2.448212810357412, 2.4439751585324614, 2.440416077772776, 2.4320514400800066, 2.4308197498321533, 2.421884107589722, 2.4172281662623085, 2.412824869155884, 2.4117210745811466, 2.4075473586718252, 2.3978896260261533, 2.3998071392377214, 2.395369712511699, 2.3978523770968123, 2.3925637722015387, 2.3897788127263397, 2.3870200117429103, 2.3887580474217724, 2.3860849181811017, 2.384997506936391, 2.38062425851822, 2.3826677401860556, 2.383157376448314, 2.37910249233246, 2.383857889970143, 2.384961362679799, 2.380054040749867, 2.3855806271235145, 2.3840137600898745, 2.3778319358825697, 2.379027660687763, 2.38316376209259, 2.384721314907074, 2.380965443452199, 2.381338854630789, 2.3836936871210734, 2.3831540346145625, 2.380185063680013, 2.3807137052218112, 2.3813689152399693, 2.3835278431574514, 2.37959532737732, 2.382967762152354, 2.3836668650309236, 2.381434297561646, 2.3804805199305212, 2.381580471992492, 2.3822586854298913, 2.379089653491974, 2.3807091832160956, 2.381870969136555, 2.3798173149426787, 2.3794298728307086, 2.381345252195994, 2.3822954177856452, 2.382193764050802, 2.381048150857289, 2.3813748280207316, 2.385103809833527, 2.3831130305926, 2.380899898211161, 2.3806723316510503, 2.381666310628255, 2.379486616452535, 2.3830430905024214, 2.3827001055081687, 2.380601569016775, 2.3800806562105805, 2.3824267268180845, 2.3819791316986083, 2.383115923404693, 2.384351499875387, 2.3829209725062053, 2.379866683483124, 2.380356828371684, 2.380315454800924, 2.3807978828748064, 2.3803604801495872, 2.3800261418024693, 2.38436914285024, 2.3827769200007123], 'train_acc': [11.428382742875428, 19.81109240267352, 21.916899799096367, 23.127133911850745, 23.664014794077087, 24.12251338351828, 24.571110281868332, 24.579231275014525, 25.13786304423774, 25.367950262241187, 25.537322986982918, 25.522968251339815, 25.937572828852385, 25.986621889285438, 26.277249112814754, 26.3769148014162, 26.51717475607131, 26.75287245839726, 26.87724171796593, 27.173748155565193, 27.410457722718174, 27.321634994955033, 27.48651925139502, 27.532745937449036, 27.85942661397382, 27.906157493011925, 28.352023837291338, 28.237164277757103, 28.41658145786018, 28.517155492868692, 28.61597767861428, 28.804136798755515, 28.730479451432597, 28.91441020508231, 28.750232508496474, 29.15816566051798, 28.898501650271555, 29.01508050657396, 29.005511096342403, 29.166704083876322, 29.13779100185787, 29.083470399701387, 29.436808715452077, 29.22384420646624, 29.021949407383936, 29.18543412626249, 29.02496599588317, 28.884363053091185, 29.29886032622705, 29.187712549168733, 28.94040672481155, 29.019194357708866, 29.180837702576998, 29.118373235897106, 29.053329145092658, 29.075837345778112, 29.09129283322873, 29.095368189418387, 29.28772772489852, 29.205517928623117, 29.149602466098205, 28.873468454703783, 28.99851185803154, 29.05293842501512, 29.184960963372298, 28.974156061862946, 29.158820032538994, 29.31007284008756, 29.061343124065157, 29.059310821459317, 28.981492143495025, 29.160140029021935, 28.936135665241487, 29.11090312030269, 29.087570405415253, 29.263923967520824, 29.104479367816644, 29.1307855327197, 28.966885007284173, 29.261199041337797, 29.133173679888817, 29.184933928630105, 29.02235048890504, 29.150869638871384, 29.067201911679835, 28.988304393336456, 29.275971265698708, 29.12631676003783, 29.007231073469335, 29.026531263530615, 29.079612915557522, 29.225300224935687, 29.142127092848483, 29.088022506290084, 29.1224603374439, 29.212014852725286, 29.141833995800503, 29.118127074818496, 29.007602466959206, 29.224712683734726], 'val_loss': [3.1164290110270185, 2.8089978496233625, 2.6931212147076926, 2.642825861771901, 2.606728812058767, 2.5857921640078234, 2.5677661299705505, 2.5515411098798118, 2.5386233925819397, 2.5258121093114223, 2.52110215028127, 2.521039088567098, 2.5112783114115396, 2.505069136619568, 2.4876665671666465, 2.4860515197118125, 2.479662537574768, 2.4769924481709795, 2.478318909804026, 2.469059328238169, 2.463984390099843, 2.460095743338267, 2.455775002638499, 2.4566204746564226, 2.4436935583750405, 2.4436465303103128, 2.4333839615186053, 2.436308304468791, 2.4404140313466387, 2.431057075659434, 2.4220780531565347, 2.424895505110423, 2.4242172042528787, 2.431257784366608, 2.417743782202403, 2.422770003477732, 2.4263137777646384, 2.413644293944041, 2.4236726959546404, 2.4192378719647727, 2.4225030938784284, 2.4228825370470686, 2.415985544522603, 2.4126091798146567, 2.4184021155039472, 2.416945993900299, 2.421400487422943, 2.422949473063151, 2.4234702984491987, 2.4216315348943076, 2.4178385138511658, 2.425035397211711, 2.4189638892809544, 2.419054528077443, 2.4224597613016767, 2.4260657032330832, 2.417381207148234, 2.4182060956954956, 2.4067189892133083, 2.423804064591726, 2.423402726650238, 2.4181370933850608, 2.4134914080301924, 2.423505405584971, 2.411700228850047, 2.422227462132772, 2.4249356190363565, 2.4135369261105852, 2.419910947481791, 2.4087442557017007, 2.4240721265474954, 2.4191485246022544, 2.41381977001826, 2.4222267270088205, 2.4257183869679766, 2.4200066725413003, 2.41445243358612, 2.4210774103800454, 2.4242344697316494, 2.4190611044565835, 2.411325534184774, 2.422772407531738, 2.431810716787974, 2.4189119736353555, 2.429151952266693, 2.4200995365778604, 2.422409613927205, 2.423869828383128, 2.4235117634137473, 2.4207422733306885, 2.410756786664327, 2.4235662420590716, 2.411949773629506, 2.4228553771972656, 2.4251383145650225, 2.4266469677289324, 2.4174031019210815, 2.421556770801544, 2.412984212239583, 2.424062192440033], 'val_acc': [17.32829715469425, 20.915193965918025, 22.42237321243496, 22.99699713860598, 23.53385258014746, 24.308061887784046, 24.66119313139484, 24.579844997274964, 24.742479223629655, 25.715005693433753, 25.2522534705642, 25.716049668795574, 25.907558547656286, 25.7967963313141, 26.41816670924101, 26.363651711328732, 26.93816447048376, 26.62621405021616, 26.402287501072134, 26.49908304556279, 26.28691257177931, 27.263083625285603, 27.21926311782413, 27.43971349669941, 27.63968985441155, 27.29214276938826, 27.791172650676913, 28.205034573404454, 27.89365653361157, 28.271112143571578, 27.830477697162205, 28.18518087784696, 27.960608194927154, 28.187622246608115, 28.478142062736655, 28.111730679924165, 28.333866004749034, 28.533000558949844, 28.22119128577524, 28.4699694995805, 28.387535945265913, 28.23027547637805, 28.90470614418072, 28.31929687929565, 28.162478082924565, 28.744563210974558, 28.27683170405021, 27.972790426770736, 28.687592217134092, 28.249492619534088, 28.684182280169473, 27.894732959672368, 28.415583395575943, 28.485674827259146, 28.673605235482356, 28.192947867965838, 28.30416050291177, 28.396207998623346, 28.794960249006213, 28.43431918338404, 28.18289771101886, 28.54477814343276, 28.799005667824332, 28.311304952096332, 28.605393895755146, 28.282270417259745, 28.425311417273008, 28.536495943587926, 28.519539294285604, 28.65183665172639, 28.294019927967913, 28.478517453196595, 28.30093045694829, 28.17634453248357, 28.32417740265568, 28.56518591824973, 28.350220868445074, 28.6973143842552, 28.281050283569268, 28.608669847263997, 28.971594093099604, 28.467717024519914, 28.269788933291736, 28.171818619813656, 28.001294422205458, 28.16545240666893, 28.309441384256722, 28.15346480832423, 28.357392490729207, 28.39635774520662, 28.79134486089179, 28.347109331308566, 28.686726100910466, 28.389615683122106, 28.458829712154134, 28.319545874324582, 28.107210001693215, 28.123297266919995, 28.537627649840076, 28.0596161716305], 'test_loss': -1, 'test_acc': -1, 'model_filename': './64_hidden.pt'}, SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 64, batch_first=True)\n",
            "  (fc): Linear(in_features=64, out_features=88, bias=True)\n",
            "))), (128, (Namespace(batch_size=128, catch_keyboard_interrupt=True, char_embedding_size=32, cuda=True, device=device(type='cuda'), early_stopping_criteria=5, expand_filepaths_to_save_dir=True, learning_rate=0.001, model_state_file='/model.pth', num_epochs=100, reload_from_files=False, rnn_hidden_size=128, save_dir='/', seed=1337, surname_csv='https://raw.githubusercontent.com/jasoriya/CS6120-PS2-support/master/data/surnames/surnames_with_splits.csv', vectorizer_file='/vectorizer.json'), <data_vectorization.SurnameDataset object at 0x7f998e507f60>, <data_vectorization.SurnameVectorizer object at 0x7f998e507e10>, {'stop_early': False, 'early_stopping_step': 2, 'early_stopping_best_val': 2.2879831194877625, 'learning_rate': 0.001, 'epoch_index': 99, 'train_loss': [3.4494915525118515, 2.7865005970001206, 2.647130668163299, 2.5814037164052324, 2.5407037377357473, 2.509828706582388, 2.4878111521403, 2.4677350521087655, 2.4460350513458247, 2.4266769051551815, 2.41282526254654, 2.3993895729382833, 2.3855696678161613, 2.3734933614730838, 2.359681602319081, 2.3496698975563044, 2.33982175985972, 2.3263169129689536, 2.315865655740101, 2.306939013799031, 2.2969867308934524, 2.285880573590597, 2.279540657997132, 2.272706031799315, 2.2602537075678506, 2.2551905035972593, 2.2518916805585225, 2.239535780747732, 2.2290031035741165, 2.2221842288970945, 2.216769270102183, 2.21854749917984, 2.210285786787669, 2.2015355388323457, 2.201525863011678, 2.19951357046763, 2.198762532075245, 2.1981238524119053, 2.2003415028254176, 2.197007592519124, 2.190961213906606, 2.1915360411008193, 2.1889640887578325, 2.191331017017364, 2.1931641181310013, 2.1910359938939408, 2.1889830430348716, 2.190689178307851, 2.1900377988815314, 2.189710410435995, 2.1912014802296964, 2.1899912516276046, 2.1918132066726685, 2.190891309579213, 2.1899259050687165, 2.1924133419990537, 2.190817658106486, 2.1908758958180745, 2.190010929107667, 2.19042847553889, 2.1933181246121722, 2.187946271896362, 2.1893499692281084, 2.1899015982945764, 2.19114846388499, 2.1901730616887405, 2.189586444695791, 2.1900268554687514, 2.1914702097574863, 2.1896095991134645, 2.188054720560711, 2.1900530735651658, 2.1941305041313175, 2.192048486073812, 2.1913492361704505, 2.190167065461477, 2.190847023328146, 2.190389613310496, 2.186514147122702, 2.1867644349733992, 2.188887949784596, 2.192343819141388, 2.188281985123952, 2.1921143809954318, 2.1923512419064846, 2.1911208311716712, 2.1884050846099856, 2.1929435014724743, 2.1911608695983884, 2.188521230220794, 2.1893281579017634, 2.1911083896954855, 2.1928895990053805, 2.1912374019622805, 2.19100882212321, 2.1915184100468954, 2.189832139015198, 2.1905324021975208, 2.187841324011484, 2.1919434110323586], 'train_acc': [15.470156503784246, 21.52536148566234, 23.583510774213394, 24.499385307479724, 24.93908284614829, 25.707211241606384, 25.99070063979844, 26.259477716304882, 26.86510681108913, 27.322578547835068, 27.737584836682238, 28.106185214668894, 28.615259299867663, 29.009866798531352, 29.276307803668534, 29.451530360730985, 29.78482168268753, 30.243508998676326, 30.65808658858001, 30.513160803016415, 31.075815640319135, 31.513451116735098, 31.73138300536603, 31.97891106436797, 32.24549979106507, 32.370676657525344, 32.53733195254375, 32.85694709461579, 33.096026478346744, 33.374489211631385, 33.605814683678936, 33.44918385323399, 33.87689379381192, 34.098840090213336, 34.0293695364735, 34.128921571918994, 34.042534202382726, 33.964596621504526, 33.96044483647827, 34.19448077432444, 34.19132275030244, 34.26898093710772, 34.453759227109835, 34.37908302565552, 34.267973234933116, 34.18959215415778, 34.21899261915106, 34.21232346434064, 34.13789155654273, 34.21624682821765, 34.38565233588721, 34.182036326900175, 34.19410605161686, 34.166220589383066, 34.417534612975224, 34.440240204216, 34.17120288780248, 34.290190487879826, 34.37745960289891, 34.2165389792205, 34.41040602889957, 34.1916494219722, 34.261252545108064, 34.312030447724155, 34.40981981885303, 34.26697095614016, 34.27144245711917, 34.2356464423617, 34.33430273507515, 34.31684599496554, 34.48095632260412, 34.21763008675133, 34.18225284374314, 34.51814638296305, 34.272967620062616, 34.33796702237352, 34.34152621078371, 34.18122893817409, 34.290365751192546, 34.30019912496399, 34.20448895134698, 34.227614116005896, 34.16372316918646, 34.309390962897865, 34.39079373602903, 34.207081521832315, 34.218639422192474, 34.2764401636672, 34.28374155300774, 34.42432914419397, 34.309107252323344, 34.29882544540001, 34.39176770542233, 34.22634887332444, 34.26615229038385, 34.33967969203707, 34.33209898401002, 34.26672978673659, 34.30962777152023, 34.10832014035082], 'val_loss': [2.923828224341075, 2.697867274284363, 2.609746833642324, 2.5684112310409546, 2.529327988624573, 2.510590970516205, 2.491530895233154, 2.4714548190434775, 2.4499955972035723, 2.4376314878463745, 2.424643596013387, 2.4161544243494673, 2.39489616950353, 2.3887886206309004, 2.3774006168047586, 2.373714466889699, 2.365005135536194, 2.3610161741574602, 2.3544329404830933, 2.337699512640635, 2.335081934928894, 2.3362823923428855, 2.3257535696029663, 2.317200720310211, 2.321056207021077, 2.3141918381055193, 2.3181199034055076, 2.3141016165415444, 2.3144728740056357, 2.3030266563097634, 2.297710041205088, 2.305087983608246, 2.304880956808726, 2.3047401110331216, 2.2985119819641113, 2.295286695162455, 2.2947065035502114, 2.2879831194877625, 2.299796203772227, 2.304492235183716, 2.2973328034083056, 2.2892501155535383, 2.2896325588226323, 2.296708126862844, 2.2995495796203613, 2.3003144860267635, 2.295415222644806, 2.2921126286188764, 2.288228591283162, 2.298517286777496, 2.297998428344726, 2.29839026927948, 2.297389646371206, 2.302991946538289, 2.288572033246358, 2.297387440999349, 2.290770053863526, 2.289782404899597, 2.2940577864646907, 2.2987261811892195, 2.2943849960962934, 2.302243729432424, 2.2991128365198774, 2.2916288177172346, 2.29387762149175, 2.2920131285985312, 2.3042763670285544, 2.296597560246785, 2.3068515062332153, 2.3035584092140198, 2.2985520164171853, 2.2996889352798466, 2.294313132762909, 2.2996800939242044, 2.3026134371757503, 2.2986497282981873, 2.2988198598225913, 2.295394798119863, 2.2894132733345036, 2.3020487825075784, 2.2973754405975346, 2.2959051330884295, 2.290907343228658, 2.2978877027829485, 2.2961753408114114, 2.3008984724680586, 2.2907040317853293, 2.304025073846181, 2.288270314534505, 2.2951912681261697, 2.306665738423665, 2.2907699743906655, 2.2997620900472007, 2.305204629898071, 2.29997456073761, 2.294528941313426, 2.302203933397929, 2.2926497658093767, 2.2957778374354048, 2.3009795347849527], 'val_acc': [20.304679667032367, 22.25483113041106, 23.7747301282937, 24.634991737500773, 24.82062800294206, 25.466826237453088, 25.888204573332423, 26.053202595327043, 26.708968594786935, 27.15662212418145, 27.26755737134627, 27.579074874304833, 28.214387581556895, 28.750811304730018, 28.679938929192204, 29.269183875348965, 29.43688619961006, 29.279749465297147, 29.86046170590688, 30.304912721575754, 30.890674964437242, 30.102621094394415, 30.526470393393083, 30.928617361889543, 30.841751244721543, 31.081149832351322, 30.700791491241162, 31.501167576290218, 31.05966929698286, 31.573647756245187, 31.906932587270607, 31.542197578890686, 31.56990956700283, 31.898871673785017, 31.830378135992763, 31.453668824946025, 32.06495190624764, 32.43427746437087, 31.726799730063288, 31.80169405713668, 31.854797875220864, 31.733699218884986, 31.678759408482847, 32.00361987414781, 31.991003202652784, 31.874128930312626, 31.940609634424117, 31.46921104344309, 31.82037370026749, 31.970274874290087, 31.586474864387778, 31.979386541141093, 32.08982035240857, 31.984632058315484, 32.07843684866784, 32.037126824555344, 32.287396499397445, 32.126186053050624, 31.864729114112826, 31.831311097582546, 31.57336347171593, 31.970326610120605, 31.69528561592112, 31.912986340252566, 31.585281849283017, 31.872887340959636, 31.78132712377154, 31.628834674576204, 31.783033740979477, 31.65498946838816, 32.055050986358985, 32.00957108678079, 31.962864363351127, 31.78701803738611, 31.925458748005262, 31.810281197910385, 31.605670036216498, 32.09342394532254, 31.87039209118047, 31.898823265367078, 31.98960390355348, 31.9523345482387, 31.78555158738947, 31.9029993938531, 31.79205231981163, 31.36289837642889, 31.859423431355296, 31.967784489513008, 31.811417795306113, 31.903418932793095, 31.473718577594987, 31.78372188705444, 31.57632965338403, 31.926306707095275, 31.938774604622942, 31.792439213960876, 31.858787134860282, 31.697343557221867, 31.583036275195422, 31.91487363338637], 'test_loss': -1, 'test_acc': -1, 'model_filename': './128_hidden.pt'}, SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 128, batch_first=True)\n",
            "  (fc): Linear(in_features=128, out_features=88, bias=True)\n",
            "))), (256, (Namespace(batch_size=128, catch_keyboard_interrupt=True, char_embedding_size=32, cuda=True, device=device(type='cuda'), early_stopping_criteria=5, expand_filepaths_to_save_dir=True, learning_rate=0.001, model_state_file='/model.pth', num_epochs=100, reload_from_files=False, rnn_hidden_size=256, save_dir='/', seed=1337, surname_csv='https://raw.githubusercontent.com/jasoriya/CS6120-PS2-support/master/data/surnames/surnames_with_splits.csv', vectorizer_file='/vectorizer.json'), <data_vectorization.SurnameDataset object at 0x7f998e423f60>, <data_vectorization.SurnameVectorizer object at 0x7f998e494d68>, {'stop_early': False, 'early_stopping_step': 0, 'early_stopping_best_val': 2.219927350680033, 'learning_rate': 0.001, 'epoch_index': 99, 'train_loss': [3.2443594773610442, 2.6475321888923644, 2.5484076658884702, 2.4963844458262123, 2.45500032901764, 2.425254297256469, 2.3942105650901784, 2.3692297498385115, 2.3425771514574674, 2.3199643095334377, 2.29740827480952, 2.2791858355204266, 2.259404253959655, 2.235950517654419, 2.2172911842664083, 2.199484121799468, 2.180561498800912, 2.164170614878336, 2.1503529230753577, 2.1325664957364405, 2.1140473524729404, 2.0974721749623613, 2.084442782402039, 2.061679754654566, 2.0479388674100236, 2.0395968019962316, 2.031437714894612, 2.0177374720573433, 2.013348829746247, 2.0048089047273008, 2.003487040599188, 1.9953369001547498, 1.9977095127105717, 1.9927982151508328, 1.99123161037763, 1.9905509650707252, 1.9811160524686173, 1.984534182151159, 1.9854535102844242, 1.986158432563146, 1.9841101984182994, 1.9848406672477723, 1.9849656879901887, 1.981745245059331, 1.9817308604717252, 1.982985671361287, 1.9819641451040904, 1.9827449023723605, 1.9825157046318054, 1.9865812142690027, 1.9774948894977569, 1.9817995647589364, 1.982270616292953, 1.982371606429418, 1.9830196857452393, 1.9859128077824912, 1.981654489040375, 1.9854052305221557, 1.9842007815837859, 1.981155133247376, 1.9851666629314422, 1.9825396557648975, 1.9818258821964263, 1.979461993773778, 1.9833404282728833, 1.979453784227371, 1.9827202022075652, 1.9868746499220524, 1.9780978401501965, 1.9840316653251644, 1.979656747976938, 1.9808584411938988, 1.9821578443050385, 1.9841420034567518, 1.9836915890375768, 1.9829907476902007, 1.9823403278986613, 1.9818408032258348, 1.9875801563262938, 1.9821060637633006, 1.981957447528839, 1.9828821678956352, 1.980793585379918, 1.9807299196720125, 1.9821977257728576, 1.9832159936428067, 1.982437906662623, 1.9852607965469364, 1.981940740346909, 1.9785630265871685, 1.9830079555511475, 1.9800151765346534, 1.9824031233787538, 1.9822965403397876, 1.9843320151170094, 1.9861349026362098, 1.9836127420266467, 1.978701992829641, 1.9793493767579398, 1.9815306186676023], 'train_acc': [18.05742337616775, 23.446192733661984, 24.886139084918508, 25.930291691962974, 26.702684993862444, 27.220206804282768, 27.992616227852444, 28.808628798251757, 29.50474961605683, 30.15226965561924, 30.909888660830898, 31.324720247979, 31.877439097718764, 32.397473997524955, 33.024134039401766, 33.681933302274885, 34.17276841352099, 34.67147287437897, 34.991414932661385, 35.64396371469628, 36.18482068972159, 36.59450872294167, 36.97248535234523, 37.68335651275281, 38.014188366734615, 38.11792921862572, 38.508094988283325, 38.67763154207939, 39.03483486577591, 39.17425576328277, 39.360506362174384, 39.50765596893243, 39.418134654339816, 39.585896001000236, 39.51198099119908, 39.477257387759394, 39.91819670001749, 39.53040478812713, 39.755850608642355, 39.71510650766029, 39.974571146334796, 39.92025512828714, 39.79868890705323, 39.71083496601269, 39.83789156585165, 39.84710790690614, 39.83390963060447, 39.99901449751253, 39.80821037792558, 39.65210858015673, 39.9879839414953, 39.661014565635526, 39.99986221586205, 39.7024159180698, 39.773881546273586, 39.710242236192386, 39.97985643737592, 39.955966979791, 39.55753919503154, 39.853204006911966, 39.838037905151445, 39.791020701421026, 39.670082416073335, 39.898141067121145, 39.78769024814243, 39.7444806869812, 39.75805302114008, 39.6405906984823, 39.789092415139464, 39.79022290335168, 39.7921474432796, 39.83461159322547, 39.83411276555053, 39.6096043199078, 39.882188732363836, 39.66177681094732, 39.708512044604994, 39.96761207070628, 39.74583359498933, 39.84072569790206, 39.90099964855616, 39.85886689161679, 39.823483684418484, 39.85210783013071, 39.801699841003334, 39.77242978209471, 39.770297257636756, 39.609956252006114, 39.6833665071819, 40.02729223675183, 39.83976308559432, 39.77641982581012, 39.89761193256742, 39.876457176351906, 39.72389384024823, 39.78168069554029, 39.72043034980988, 39.84137069517307, 40.0155001262576, 39.81054761790705], 'val_loss': [2.726714352766673, 2.588902175426483, 2.5223361253738403, 2.4827051162719727, 2.456331094106038, 2.417720913887024, 2.3983320196469626, 2.372815152009328, 2.352876663208008, 2.340559979279836, 2.3247756958007812, 2.309522807598114, 2.2980569402376814, 2.27972149848938, 2.277572731177012, 2.2740449508031206, 2.2556390166282654, 2.258974134922027, 2.2447843352953587, 2.255580206712087, 2.2386466066042585, 2.2429466644922895, 2.2414686282475786, 2.23219887415568, 2.2270478208859763, 2.2327823440233865, 2.244666854540507, 2.235370914141337, 2.226514240105947, 2.2290854056676226, 2.234862724939982, 2.234660804271698, 2.240898052851359, 2.222437004248301, 2.2363508542378745, 2.2394221425056458, 2.2213523387908936, 2.2388825813929243, 2.238649487495423, 2.230916539827983, 2.22990087668101, 2.2294596831003823, 2.2371954917907715, 2.2393083373705545, 2.245593667030335, 2.2336909572283425, 2.2352761626243587, 2.2323719461758933, 2.2320078214009604, 2.2317235668500266, 2.237379590670268, 2.2332199811935425, 2.245294570922851, 2.2305016716321306, 2.2413608431816106, 2.2307518124580383, 2.219927350680033, 2.237606306870778, 2.2306777636210127, 2.2373399337132773, 2.243567983309428, 2.2417226036389666, 2.228410283724467, 2.237684408823649, 2.2468008597691855, 2.2365559935569763, 2.2348340551058454, 2.2429465850194297, 2.2468607624371844, 2.2407649954160056, 2.2290245691935224, 2.2430578072865806, 2.2381652593612675, 2.2349771658579507, 2.2242884635925293, 2.2259438037872314, 2.2450419267018638, 2.2341679930686955, 2.2430800596872964, 2.2382880051930747, 2.234028458595276, 2.228345493475597, 2.248286366462708, 2.2338128884633384, 2.2317010362943015, 2.239366372426351, 2.2402788400650024, 2.225404580434163, 2.2278091112772618, 2.2305072744687395, 2.2467065652211504, 2.2499851584434514, 2.2380759716033936, 2.235141058762868, 2.248343487580618, 2.230784555276235, 2.2281846801439924, 2.2223008076349893, 2.235609988371531, 2.2324177026748657], 'val_acc': [22.15859726892554, 24.035823215692965, 25.34861399038327, 26.15392960576082, 26.88865010379852, 27.675187581655845, 28.358042520227837, 29.104792563490122, 29.475799481249318, 29.99464087370076, 30.379175069652288, 31.02613940913025, 30.829555137774076, 31.965638778078453, 31.7434727233861, 32.11249431690043, 32.66148010404993, 32.72991769307055, 33.190701509834554, 33.17647040048417, 33.724927345525, 33.941962310791226, 34.0672199038646, 33.87932890286488, 34.150266812672626, 34.38794025925215, 34.236245147710946, 34.39557420434647, 33.85638234940279, 34.011057713927855, 34.35239845314126, 34.34648581659819, 33.66529680162124, 34.71992051828263, 34.33398297379554, 34.15750377493963, 34.49774335383571, 34.450808562153576, 34.611171738202934, 34.21883022777131, 34.657848833501035, 34.20531044280902, 34.39210641001348, 34.269379737965785, 33.96278785629843, 33.85355948388198, 33.85270231230701, 34.166791454978565, 34.04282094177374, 34.34842115867905, 34.440681405240255, 34.271326724756634, 34.000712548377386, 33.918943113394384, 33.873833969887315, 34.1647097989936, 34.88322061464242, 33.93218853733208, 34.42310609021361, 33.97137292907686, 34.21488006052353, 33.906891062809066, 34.390887473452814, 34.07271094181795, 33.97770696389032, 34.29384917591767, 34.46519105535796, 34.007890939029046, 34.317839149374024, 33.71928812321476, 34.77037057297283, 34.00795855568372, 34.23698129017293, 34.83622385838766, 34.65283837810282, 34.744655775697375, 34.2980811109033, 34.269998683506905, 33.99457225617139, 34.74091462430975, 34.532429699455065, 34.76009662064276, 33.896924078416646, 34.44179358744562, 34.23952763484072, 34.45566165305149, 34.29627834693557, 34.513470727825165, 34.73542374969801, 34.29613891676534, 34.1100250665925, 33.817441616883926, 34.217712302038926, 34.38629261276236, 34.2652610922161, 34.87779309895087, 34.8766864458573, 34.54423936841332, 34.61198050168792, 34.29574610215883], 'test_loss': -1, 'test_acc': -1, 'model_filename': './256_hidden.pt'}, SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 256, batch_first=True)\n",
            "  (fc): Linear(in_features=256, out_features=88, bias=True)\n",
            ")))])\n",
            "/content\n",
            "128_hidden.pt  256_hidden.pt  32_hidden.pt  64_hidden.pt  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N7T8c4pYqch"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "def perplexity(rnn_sizes):\n",
        "  rnn_sizes=rnn_sizes\n",
        "  if rnn_sizes not in [32,64,128,256]:\n",
        "    print(\"invalid hidden layer size\", rnn_sizes)\n",
        "    exit(1)\n",
        "  args, dataset, vectorizer, train_state, model=model_rnn[rnn_sizes]\n",
        "  #dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
        "  #dataset.save_vectorizer(args.vectorizer_file)\n",
        "  #vectorizer = dataset.get_vectorizer()\n",
        "  model = SurnameGenerationModel(char_embedding_size=args.char_embedding_size,\n",
        "                               char_vocab_size=len(vectorizer.char_vocab),\n",
        "                               rnn_hidden_size=args.rnn_hidden_size,\n",
        "                               padding_idx=vectorizer.char_vocab.mask_index)\n",
        "  print(model)\n",
        "  mask_index = vectorizer.char_vocab.mask_index\n",
        "  \n",
        "  model.load_state_dict(torch.load(f'{rnn_sizes}_hidden.pt'))\n",
        "  model = model.to(args.device)\n",
        " \n",
        "  perplexity=[]\n",
        "  for i in range(1,20):\n",
        "    #train_state['epoch_index'] = epoch_index\n",
        "    # Iterate over training dataset\n",
        "    # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "    dataset.set_split('test')\n",
        "    batch_generator = generate_batches(dataset, \n",
        "                                      batch_size=args.batch_size, \n",
        "                                      device=args.device)\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    #model.train()\n",
        "    for batch_index, batch_dict in enumerate(batch_generator):\n",
        "      x_data = np.array(torch.Tensor.clone(batch_dict['x_data'].cpu()))#\n",
        "      for j in range(i,19):\n",
        "        for k in range(x_data.shape[0]):\n",
        "          x_data[k][j]=0\n",
        "      x_data = torch.Tensor(x_data).type(torch.LongTensor).to(args.device)\n",
        "      y_pred=model(x_in=x_data)\n",
        "      # step 3. compute the loss\n",
        "      #loss = F.cross_entropy(y_pred,batch_dict['y_target'],mask_index)\n",
        "      loss= sequence_loss(y_pred,batch_dict['y_target'],mask_index)\n",
        "      # step 4. use loss to produce gradients\n",
        "      running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "      acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "      running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "    #perplexity.append(torch.exp(loss))\n",
        "    perplexity.append(2**running_loss)\n",
        "  return perplexity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlDVIkFEsU9-",
        "outputId": "6f280c0f-62cd-4df7-aee0-4c832d1b0982"
      },
      "source": [
        "perplexity_dict={}\n",
        "for rnn_hidden_size in [32,64,128,256]:\n",
        "  perplexity_dict[rnn_hidden_size]=perplexity(rnn_hidden_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 32, batch_first=True)\n",
            "  (fc): Linear(in_features=32, out_features=88, bias=True)\n",
            ")\n",
            "SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 64, batch_first=True)\n",
            "  (fc): Linear(in_features=64, out_features=88, bias=True)\n",
            ")\n",
            "SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 128, batch_first=True)\n",
            "  (fc): Linear(in_features=128, out_features=88, bias=True)\n",
            ")\n",
            "SurnameGenerationModel(\n",
            "  (char_emb): Embedding(88, 32, padding_idx=0)\n",
            "  (rnn): GRU(32, 256, batch_first=True)\n",
            "  (fc): Linear(in_features=256, out_features=88, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "lJ3kM8EgkIlZ",
        "outputId": "a04c8ebe-0084-4d89-9daf-b6b1515caa3c"
      },
      "source": [
        "for rnn_hidden_size in [32,64,128,256]:\n",
        "  print(\"rnn_size=\",rnn_hidden_size,\" // Perplexity\" ,perplexity_dict[rnn_hidden_size])\n",
        "\n",
        "#import matplotlib as plt\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "plt.figure(facecolor=\"pink\")\n",
        "for k,v in perplexity_dict.items():\n",
        "  plt.plot(range(0,19),v,label=\"Rnn_size\"+str(k))\n",
        "plt.xlabel(\"Prediction after character no.\")\n",
        "plt.ylabel(\"perplexity\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn_size= 32  // Perplexity [8.557617847995166, 8.155891715293867, 7.862915753573629, 7.455238640600632, 7.0204597828408115, 6.6197141972092375, 6.317571227772091, 6.079565095886211, 5.937496492988748, 5.889404401000829, 5.849023394411432, 5.842519668823394, 5.835220239926828, 5.798650194506488, 5.854616989662379, 5.818697089776425, 5.847138174670977, 5.863903838651079, 5.826290050305066]\n",
            "rnn_size= 64  // Perplexity [11.621891935061525, 10.751401987313336, 9.008741904926838, 8.354680158994286, 7.39021044884035, 6.622165687334325, 6.068088325794442, 5.736080566889542, 5.534537361546033, 5.4137200840293, 5.397576973757303, 5.334648347256892, 5.353113006266108, 5.327733451864349, 5.331519660191599, 5.3365907176291865, 5.354179854213199, 5.352306928747237, 5.3548662292439655]\n",
            "rnn_size= 128  // Perplexity [11.490425395944513, 10.294960636806893, 8.905800294633465, 8.012661810580267, 7.06865791890815, 6.252095518425041, 5.698895523897865, 5.352434964227079, 5.1091865178138605, 4.986592659438471, 4.946025730545812, 4.908927134261617, 4.920909629770709, 4.924187680720751, 4.915856674453713, 4.890025436933814, 4.935560508488042, 4.91984801074635, 4.913795936730862]\n",
            "rnn_size= 256  // Perplexity [11.84748662879282, 10.929794860364138, 9.507808229589926, 8.226237349367292, 7.181379830246309, 6.175426903263583, 5.594329763817973, 5.185085195791773, 4.91854886068535, 4.81334898468519, 4.757145534744462, 4.731472516190453, 4.705223785238767, 4.733544729919601, 4.739662380520674, 4.74778102800039, 4.729278764156199, 4.684380494447827, 4.685454474326566]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udx_uRW2EeYg"
      },
      "source": [
        "The results of this experiments are as folllows:\n",
        "There seems not much difference in models with hidden RNN size larger than 32. \n",
        "The difference starts appearing at 7 character level where higher rnn sizes perform better with one unit less perplexity.\n",
        "\n",
        "32 bit performs better initially when not enough data is available which might be because of overfitting in case of higher hidden RNNs as less data is available initially.\n",
        "As the models learn more characters the higher level RNN perform much better."
      ]
    }
  ]
}